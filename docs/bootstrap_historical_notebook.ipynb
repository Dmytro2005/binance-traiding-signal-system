{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "import os\n",
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines parameters for fetching previous candles. Specifies the symbol to fetch, timeframe, amount of candles to fetch. Configures Kafka connection details and API endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMBOLS = [\"BTCUSDT\"]\n",
    "INTERVAL = \"30m\"\n",
    "LIMIT = 21\n",
    "KAFKA_TOPIC = \"binance_kline\"\n",
    "KAFKA_BOOTSTRAP_SERVERS = \"localhost:9092\"\n",
    "BINANCE_API_URL = \"https://api.binance.com/api/v3/klines\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieves candlestick data from Binance's public REST API. Sends a GET request with symbol, interval, and limit parameters to fetch the most recent candles. The API returns raw kline data as arrays, which are parsed and transformed into structured dictionaries containing OHLCV fields (open, high, low, close, volume), trading metrics (number_of_trades, taker volumes), and metadata (symbol, interval, ingestion timestamp). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_historical_candles(symbol, interval=\"30m\", limit=21):\n",
    "    params = {\n",
    "        \"symbol\": symbol,\n",
    "        \"interval\": interval,\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(BINANCE_API_URL, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        candles = []\n",
    "        \n",
    "        for kline in data:\n",
    "            candle = {\n",
    "                \"open_time\": int(kline[0]), \n",
    "                \"open\": float(kline[1]),\n",
    "                \"high\": float(kline[2]),\n",
    "                \"low\": float(kline[3]),\n",
    "                \"close\": float(kline[4]),\n",
    "                \"volume\": float(kline[5]),\n",
    "                \"quote_asset_volume\": float(kline[7]),\n",
    "                \"number_of_trades\": int(kline[8]),\n",
    "                \"taker_buy_base_asset_volume\": float(kline[9]),\n",
    "                \"taker_buy_quote_asset_volume\": float(kline[10]),\n",
    "                \"symbol\": symbol,\n",
    "                \"interval\": interval,\n",
    "                \"ingested_at\": datetime.now(timezone.utc).isoformat()\n",
    "            }\n",
    "            candles.append(candle)\n",
    "        \n",
    "        return candles\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching candles for {symbol}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publishes  candles to the Kafka topic for consumption by the inference system. Iterates through the candle list and sends each as a  message to the configured topic. Prints confirmation for each published candle showing the symbol, timestamp, and closing price for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_kafka(candles, producer):\n",
    "    for candle in candles:\n",
    "        producer.send(KAFKA_TOPIC, value=candle)\n",
    "        print(f\"Sent: {candle['symbol']} @ {candle['open_time']} | Close: {candle['close']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves fetched candles to a local JSON file as a backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(candles, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(candles, f, indent=2)\n",
    "    print(f\"Saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution of the bootstrap process supporting both Kafka publishing and JSON  storage. Initializes a Kafka producer and acknowledgment settings ('acks=all') for guaranteed delivery. If Kafka connection fails, falls back to JSON-only mode. Iterates through all configured symbols, fetching historical candles for each. Successfully retrieved data is stored in a dictionary and  published to Kafka and/or saved to local JSON files in the data/bootstrap/ dir. A delay between symbols is set prevents API rate limiting. After processing all symbols, flushes any pending Kafka messages and closes the producer connection to ensure all data is committed. Prints a summary showing how many symbols were successfully bootstrapped and the total number of candles retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kafka connection failed: NoBrokersAvailable\n",
      "Falling back to JSON-only mode\n",
      "\n",
      "Fetching BTCUSDT\n",
      "Saved to data/bootstrap/BTCUSDT_30m_bootstrap.json\n",
      "\n",
      "Bootstrap complete\n",
      "Symbols bootstrapped: 1/1\n",
      "Total candles: 21\n"
     ]
    }
   ],
   "source": [
    "use_kafka = True\n",
    "save_json = True\n",
    "\n",
    "producer = None\n",
    "if use_kafka:\n",
    "    try:\n",
    "        producer = KafkaProducer(\n",
    "            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,\n",
    "            value_serializer=lambda v: json.dumps(v).encode('utf-8'),\n",
    "            acks='all'\n",
    "        )\n",
    "        print(\"Connected to Kafka\")\n",
    "    except Exception as e:\n",
    "        print(f\"Kafka connection failed: {e}\")\n",
    "        print(\"Falling back to JSON-only mode\")\n",
    "        use_kafka = False\n",
    "\n",
    "print()\n",
    "\n",
    "all_candles = {}\n",
    "\n",
    "for symbol in SYMBOLS:\n",
    "    print(f\"Fetching {symbol}\")\n",
    "    candles = fetch_historical_candles(symbol, INTERVAL, LIMIT)\n",
    "    \n",
    "    if candles:\n",
    "        all_candles[symbol] = candles\n",
    "        \n",
    "        if use_kafka and producer:\n",
    "            send_to_kafka(candles, producer)\n",
    "        \n",
    "        if save_json:\n",
    "            os.makedirs(\"data/bootstrap\", exist_ok=True)\n",
    "            filename = f\"data/bootstrap/{symbol}_{INTERVAL}_bootstrap.json\"\n",
    "            save_to_json(candles, filename)\n",
    "        \n",
    "        print()\n",
    "        time.sleep(0.5)\n",
    "    else:\n",
    "        print(f\"Failed to fetch candles\")\n",
    "        print()\n",
    "\n",
    "if producer:\n",
    "    producer.flush()\n",
    "    producer.close()\n",
    "    print(\"Producer closed\")\n",
    "\n",
    "print(\"Bootstrap complete\")\n",
    "print(f\"Symbols bootstrapped: {len(all_candles)}/{len(SYMBOLS)}\")\n",
    "print(f\"Total candles: {sum(len(c) for c in all_candles.values())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
